# 🌍⚖️ AI Ethics Assignment – COMPAS Audit

## 📌 Overview
This repository contains my solo submission for the **Power Learn Project (PLP) AI Ethics Assignment** under the theme:  
**“Designing Responsible and Fair AI Systems.”**

The assignment evaluates understanding of **AI ethics principles**, the ability to identify and mitigate **biases**, and skills in applying ethical frameworks to real-world scenarios.  

Deliverables include **theory, case studies, a practical dataset audit, an ethical reflection, and a bonus task policy proposal**.

---

## 📂 Repository Structure

AI-Ethics-COMPAS-Audit/
│
├── compas-scores-two-years.csv # Dataset
├── compas_analysis.ipynb # Jupyter notebook for bias audit
│
├── Part1_Theory.pdf # Theoretical Q&A + Ethical principles
├── CaseStudies.pdf # Case study analyses (Hiring tool & Facial recognition)
├── COMPAS_Report.pdf # Practical audit report with findings & remediation
├── Part4_Ethical_Reflection.pdf # Personal ethical reflection
├── BonusTask_Ethical_AI_in_Healthcare.pdf # Bonus task: healthcare AI policy proposal
│
├── Final_Assignment.pdf # Consolidated final submission
└── README.md # This file

yaml
Copy code

---

## 📝 Assignment Parts

### **Part 1 – Theoretical Understanding**
- [Part1_Theory.pdf](./Part1_Theory.pdf)  

Covers:  
- Algorithmic bias (definition + examples)  
- Transparency vs Explainability  
- GDPR implications for AI development  
- Matching of AI ethical principles (justice, non-maleficence, autonomy, sustainability)  

---

### **Part 2 – Case Studies**
- [CaseStudies.pdf](./CaseStudies.pdf)  

Includes analyses of:  
1. **Amazon Hiring Tool** – identifying sources of bias, fixes, and fairness metrics.  
2. **Facial Recognition in Policing** – discussing risks (privacy, wrongful arrests) and responsible deployment policies.  

---

### **Part 3 – Practical Audit**
- [compas-scores-two-years.csv](./compas-scores-two-years.csv)  
- [compas_analysis.ipynb](./compas_analysis.ipynb)  
- [COMPAS_Report.pdf](./COMPAS_Report.pdf)  

Performed a **bias audit** of the COMPAS recidivism dataset using logistic regression and fairness metrics.  
Key findings: racial disparities in COMPAS scores, with African-American defendants disproportionately receiving higher risk scores.

---

### **Part 4 – Ethical Reflection**
- [Part4_Ethical_Reflection.pdf](./Part4_Ethical_Reflection.pdf)  

Reflects on how I will ensure **ethical AI principles** in future projects, including fairness, transparency, and human-centered design.

---

### **Bonus Task – Policy Proposal**
- [BonusTask_Ethical_AI_in_Healthcare.pdf](./BonusTask_Ethical_AI_in_Healthcare.pdf)  

A one-page guideline for **ethical AI in healthcare**, covering patient consent, bias mitigation, and transparency requirements.

---

## ⚙️ Reproduction Instructions

1. Clone the repository:
   ```bash
   git clone https://github.com/<your-username>/AI-Ethics-COMPAS-Audit.git
   cd AI-Ethics-COMPAS-Audit
